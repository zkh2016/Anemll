# ANEMLL Chat - App Store Submission

## App Name
ANEMLL Chat

## Subtitle (30 chars max)
On-Device AI Chat for Apple

## Promotional Text (170 chars max, can be updated without new build)
NEW: Gemma 3 models with 4K context, voice input, AirDrop model sharing, monolithic model support, and network drive model linking. Fast, private, on-device AI.

## Description

ANEMLL Chat brings large language models directly to your Apple device, running entirely on-device using the Apple Neural Engine. No cloud, no subscriptions, no data leaving your device.

FAST ON-DEVICE INFERENCE
Run LLMs at full speed on iPhone, iPad, Mac, and Apple Vision Pro. Models are optimized for Apple Neural Engine with up to 4,096-token context windows and real-time streaming responses.

MODELS
- Gemma 3 (270M, 1B, 4B) including QAT int4 variants with 4K context
- LLaMA 3.2 (1B)
- Qwen 2.5 & Qwen 3 (0.5B, 1.7B)
- DeepSeek R1 (8B distilled)
- More models available from the ANEMLL HuggingFace collection

Download models directly from HuggingFace within the app, or add custom models by repo ID. Monolithic and chunked model architectures supported.

VOICE INPUT
Speak your messages using built-in speech recognition. Tap the microphone to dictate, and ANEMLL Chat transcribes your voice to text.

MARKDOWN RENDERING
Responses are beautifully formatted with full Markdown support: bold, italic, headings, code blocks with syntax labels, tables, numbered and bullet lists.

THINKING MODE
Enable thinking mode for supported models (Qwen 3) to see the model's reasoning process before the final answer.

AIRDROP MODEL SHARING (Mac to iOS)
Share models from your Mac to iPhone or iPad using AirDrop. Import compiled CoreML models by drag-and-drop on Mac, then share them to your iOS devices with one tap.

LOCAL MODEL MANAGEMENT
- Import local CoreML model folders via drag-and-drop (Mac)
- Link to model folders on external or network drives without copying
- Browse and download from the ANEMLL HuggingFace model collection
- Add any ANEMLL-compatible HuggingFace model by repo ID

CONVERSATION MANAGEMENT
- Multi-turn conversations with full context history
- Persistent conversation storage
- Adjustable temperature, top-p, and max token settings
- System prompt customization

PERFORMANCE METRICS
Real-time display of tokens per second, token count, time-to-first-token, and context window utilization during generation.

PRIVACY FIRST
All inference runs locally on your device. No data is sent to any server. Model downloads come directly from HuggingFace. Your conversations never leave your device.

REQUIREMENTS
- iPhone, iPad, or Mac with Apple Silicon (M1 or later, A14 or later)
- iOS 18+ / macOS 15+
- Models range from 200MB to 4GB depending on size and quantization

## Keywords (100 chars max)
AI,LLM,chat,neural engine,on-device,private,CoreML,Gemma,LLaMA,Qwen,offline,local

## What's New (Version 0.3.8)
- NEW: Gemma 3 model family support including 4K context fast inference
- NEW: Voice input with speech-to-text dictation
- NEW: AirDrop model sharing from Mac to iPhone/iPad
- NEW: Monolithic model architecture support for faster loading
- NEW: Network drive and external drive model linking
- NEW: Thinking mode for Qwen 3 models
- Improved model management with drag-and-drop import on Mac
- Full Markdown rendering with tables, code blocks, and lists
- Enhanced download progress with speed and ETA display
- Improved error handling for unreachable linked model paths
- Performance and stability improvements

## Category
Productivity

## Age Rating
4+

## Copyright
Copyright 2024-2026 ANEMLL

## Support URL
https://github.com/anemll/anemll

## Privacy Policy URL
(required - needs to be provided)
